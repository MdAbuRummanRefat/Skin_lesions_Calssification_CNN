{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Skin_Lession_Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MdAbuRummanRefat/Skin_lesions_Calssification_CNN/blob/main/Skin_Lession_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqSL4Qcf980j",
        "outputId": "4e0e674c-4c6f-45b1-dff2-1162a73f9af7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltIjC5Zc_JdF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M98AreCPyaO",
        "outputId": "49e6b48e-3e2d-463e-fb56-491a1531ea16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "data=pd.read_csv('/content/drive/My Drive/Project/hmnist_64_64_RGB.csv')\n",
        "data.head(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0000</th>\n",
              "      <th>pixel0001</th>\n",
              "      <th>pixel0002</th>\n",
              "      <th>pixel0003</th>\n",
              "      <th>pixel0004</th>\n",
              "      <th>pixel0005</th>\n",
              "      <th>pixel0006</th>\n",
              "      <th>pixel0007</th>\n",
              "      <th>pixel0008</th>\n",
              "      <th>pixel0009</th>\n",
              "      <th>pixel0010</th>\n",
              "      <th>pixel0011</th>\n",
              "      <th>pixel0012</th>\n",
              "      <th>pixel0013</th>\n",
              "      <th>pixel0014</th>\n",
              "      <th>pixel0015</th>\n",
              "      <th>pixel0016</th>\n",
              "      <th>pixel0017</th>\n",
              "      <th>pixel0018</th>\n",
              "      <th>pixel0019</th>\n",
              "      <th>pixel0020</th>\n",
              "      <th>pixel0021</th>\n",
              "      <th>pixel0022</th>\n",
              "      <th>pixel0023</th>\n",
              "      <th>pixel0024</th>\n",
              "      <th>pixel0025</th>\n",
              "      <th>pixel0026</th>\n",
              "      <th>pixel0027</th>\n",
              "      <th>pixel0028</th>\n",
              "      <th>pixel0029</th>\n",
              "      <th>pixel0030</th>\n",
              "      <th>pixel0031</th>\n",
              "      <th>pixel0032</th>\n",
              "      <th>pixel0033</th>\n",
              "      <th>pixel0034</th>\n",
              "      <th>pixel0035</th>\n",
              "      <th>pixel0036</th>\n",
              "      <th>pixel0037</th>\n",
              "      <th>pixel0038</th>\n",
              "      <th>pixel0039</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel12249</th>\n",
              "      <th>pixel12250</th>\n",
              "      <th>pixel12251</th>\n",
              "      <th>pixel12252</th>\n",
              "      <th>pixel12253</th>\n",
              "      <th>pixel12254</th>\n",
              "      <th>pixel12255</th>\n",
              "      <th>pixel12256</th>\n",
              "      <th>pixel12257</th>\n",
              "      <th>pixel12258</th>\n",
              "      <th>pixel12259</th>\n",
              "      <th>pixel12260</th>\n",
              "      <th>pixel12261</th>\n",
              "      <th>pixel12262</th>\n",
              "      <th>pixel12263</th>\n",
              "      <th>pixel12264</th>\n",
              "      <th>pixel12265</th>\n",
              "      <th>pixel12266</th>\n",
              "      <th>pixel12267</th>\n",
              "      <th>pixel12268</th>\n",
              "      <th>pixel12269</th>\n",
              "      <th>pixel12270</th>\n",
              "      <th>pixel12271</th>\n",
              "      <th>pixel12272</th>\n",
              "      <th>pixel12273</th>\n",
              "      <th>pixel12274</th>\n",
              "      <th>pixel12275</th>\n",
              "      <th>pixel12276</th>\n",
              "      <th>pixel12277</th>\n",
              "      <th>pixel12278</th>\n",
              "      <th>pixel12279</th>\n",
              "      <th>pixel12280</th>\n",
              "      <th>pixel12281</th>\n",
              "      <th>pixel12282</th>\n",
              "      <th>pixel12283</th>\n",
              "      <th>pixel12284</th>\n",
              "      <th>pixel12285</th>\n",
              "      <th>pixel12286</th>\n",
              "      <th>pixel12287</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>191</td>\n",
              "      <td>152</td>\n",
              "      <td>194</td>\n",
              "      <td>191</td>\n",
              "      <td>153</td>\n",
              "      <td>195</td>\n",
              "      <td>192</td>\n",
              "      <td>149</td>\n",
              "      <td>192</td>\n",
              "      <td>194</td>\n",
              "      <td>151</td>\n",
              "      <td>188</td>\n",
              "      <td>193</td>\n",
              "      <td>149</td>\n",
              "      <td>182</td>\n",
              "      <td>193</td>\n",
              "      <td>150</td>\n",
              "      <td>181</td>\n",
              "      <td>195</td>\n",
              "      <td>154</td>\n",
              "      <td>185</td>\n",
              "      <td>195</td>\n",
              "      <td>156</td>\n",
              "      <td>189</td>\n",
              "      <td>203</td>\n",
              "      <td>164</td>\n",
              "      <td>196</td>\n",
              "      <td>206</td>\n",
              "      <td>166</td>\n",
              "      <td>203</td>\n",
              "      <td>209</td>\n",
              "      <td>165</td>\n",
              "      <td>201</td>\n",
              "      <td>211</td>\n",
              "      <td>166</td>\n",
              "      <td>206</td>\n",
              "      <td>209</td>\n",
              "      <td>165</td>\n",
              "      <td>206</td>\n",
              "      <td>203</td>\n",
              "      <td>...</td>\n",
              "      <td>202</td>\n",
              "      <td>167</td>\n",
              "      <td>183</td>\n",
              "      <td>199</td>\n",
              "      <td>159</td>\n",
              "      <td>175</td>\n",
              "      <td>189</td>\n",
              "      <td>141</td>\n",
              "      <td>148</td>\n",
              "      <td>184</td>\n",
              "      <td>131</td>\n",
              "      <td>136</td>\n",
              "      <td>180</td>\n",
              "      <td>128</td>\n",
              "      <td>136</td>\n",
              "      <td>179</td>\n",
              "      <td>127</td>\n",
              "      <td>141</td>\n",
              "      <td>176</td>\n",
              "      <td>129</td>\n",
              "      <td>149</td>\n",
              "      <td>175</td>\n",
              "      <td>127</td>\n",
              "      <td>145</td>\n",
              "      <td>179</td>\n",
              "      <td>136</td>\n",
              "      <td>157</td>\n",
              "      <td>182</td>\n",
              "      <td>146</td>\n",
              "      <td>164</td>\n",
              "      <td>185</td>\n",
              "      <td>154</td>\n",
              "      <td>180</td>\n",
              "      <td>186</td>\n",
              "      <td>156</td>\n",
              "      <td>184</td>\n",
              "      <td>182</td>\n",
              "      <td>152</td>\n",
              "      <td>173</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24</td>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>14</td>\n",
              "      <td>28</td>\n",
              "      <td>37</td>\n",
              "      <td>24</td>\n",
              "      <td>46</td>\n",
              "      <td>61</td>\n",
              "      <td>44</td>\n",
              "      <td>70</td>\n",
              "      <td>90</td>\n",
              "      <td>66</td>\n",
              "      <td>97</td>\n",
              "      <td>111</td>\n",
              "      <td>83</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>98</td>\n",
              "      <td>129</td>\n",
              "      <td>144</td>\n",
              "      <td>112</td>\n",
              "      <td>141</td>\n",
              "      <td>161</td>\n",
              "      <td>131</td>\n",
              "      <td>159</td>\n",
              "      <td>169</td>\n",
              "      <td>138</td>\n",
              "      <td>165</td>\n",
              "      <td>171</td>\n",
              "      <td>135</td>\n",
              "      <td>159</td>\n",
              "      <td>173</td>\n",
              "      <td>135</td>\n",
              "      <td>156</td>\n",
              "      <td>178</td>\n",
              "      <td>138</td>\n",
              "      <td>164</td>\n",
              "      <td>178</td>\n",
              "      <td>...</td>\n",
              "      <td>176</td>\n",
              "      <td>132</td>\n",
              "      <td>147</td>\n",
              "      <td>163</td>\n",
              "      <td>121</td>\n",
              "      <td>129</td>\n",
              "      <td>143</td>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "      <td>129</td>\n",
              "      <td>89</td>\n",
              "      <td>90</td>\n",
              "      <td>111</td>\n",
              "      <td>76</td>\n",
              "      <td>74</td>\n",
              "      <td>92</td>\n",
              "      <td>60</td>\n",
              "      <td>64</td>\n",
              "      <td>69</td>\n",
              "      <td>46</td>\n",
              "      <td>56</td>\n",
              "      <td>44</td>\n",
              "      <td>27</td>\n",
              "      <td>43</td>\n",
              "      <td>30</td>\n",
              "      <td>16</td>\n",
              "      <td>34</td>\n",
              "      <td>27</td>\n",
              "      <td>14</td>\n",
              "      <td>30</td>\n",
              "      <td>26</td>\n",
              "      <td>15</td>\n",
              "      <td>29</td>\n",
              "      <td>27</td>\n",
              "      <td>15</td>\n",
              "      <td>28</td>\n",
              "      <td>24</td>\n",
              "      <td>13</td>\n",
              "      <td>25</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>185</td>\n",
              "      <td>129</td>\n",
              "      <td>140</td>\n",
              "      <td>192</td>\n",
              "      <td>136</td>\n",
              "      <td>151</td>\n",
              "      <td>198</td>\n",
              "      <td>142</td>\n",
              "      <td>156</td>\n",
              "      <td>198</td>\n",
              "      <td>140</td>\n",
              "      <td>154</td>\n",
              "      <td>199</td>\n",
              "      <td>141</td>\n",
              "      <td>158</td>\n",
              "      <td>199</td>\n",
              "      <td>141</td>\n",
              "      <td>159</td>\n",
              "      <td>205</td>\n",
              "      <td>147</td>\n",
              "      <td>162</td>\n",
              "      <td>205</td>\n",
              "      <td>151</td>\n",
              "      <td>167</td>\n",
              "      <td>208</td>\n",
              "      <td>154</td>\n",
              "      <td>171</td>\n",
              "      <td>207</td>\n",
              "      <td>147</td>\n",
              "      <td>161</td>\n",
              "      <td>204</td>\n",
              "      <td>146</td>\n",
              "      <td>153</td>\n",
              "      <td>207</td>\n",
              "      <td>154</td>\n",
              "      <td>161</td>\n",
              "      <td>209</td>\n",
              "      <td>156</td>\n",
              "      <td>163</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>199</td>\n",
              "      <td>156</td>\n",
              "      <td>175</td>\n",
              "      <td>190</td>\n",
              "      <td>147</td>\n",
              "      <td>171</td>\n",
              "      <td>194</td>\n",
              "      <td>154</td>\n",
              "      <td>183</td>\n",
              "      <td>197</td>\n",
              "      <td>152</td>\n",
              "      <td>172</td>\n",
              "      <td>175</td>\n",
              "      <td>129</td>\n",
              "      <td>140</td>\n",
              "      <td>160</td>\n",
              "      <td>117</td>\n",
              "      <td>132</td>\n",
              "      <td>163</td>\n",
              "      <td>127</td>\n",
              "      <td>141</td>\n",
              "      <td>161</td>\n",
              "      <td>128</td>\n",
              "      <td>140</td>\n",
              "      <td>161</td>\n",
              "      <td>128</td>\n",
              "      <td>144</td>\n",
              "      <td>155</td>\n",
              "      <td>122</td>\n",
              "      <td>139</td>\n",
              "      <td>152</td>\n",
              "      <td>120</td>\n",
              "      <td>138</td>\n",
              "      <td>144</td>\n",
              "      <td>113</td>\n",
              "      <td>123</td>\n",
              "      <td>115</td>\n",
              "      <td>81</td>\n",
              "      <td>84</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "      <td>19</td>\n",
              "      <td>36</td>\n",
              "      <td>19</td>\n",
              "      <td>30</td>\n",
              "      <td>64</td>\n",
              "      <td>38</td>\n",
              "      <td>50</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>71</td>\n",
              "      <td>111</td>\n",
              "      <td>71</td>\n",
              "      <td>87</td>\n",
              "      <td>130</td>\n",
              "      <td>91</td>\n",
              "      <td>106</td>\n",
              "      <td>150</td>\n",
              "      <td>114</td>\n",
              "      <td>129</td>\n",
              "      <td>160</td>\n",
              "      <td>116</td>\n",
              "      <td>124</td>\n",
              "      <td>167</td>\n",
              "      <td>110</td>\n",
              "      <td>111</td>\n",
              "      <td>168</td>\n",
              "      <td>100</td>\n",
              "      <td>101</td>\n",
              "      <td>176</td>\n",
              "      <td>110</td>\n",
              "      <td>116</td>\n",
              "      <td>184</td>\n",
              "      <td>131</td>\n",
              "      <td>144</td>\n",
              "      <td>191</td>\n",
              "      <td>141</td>\n",
              "      <td>152</td>\n",
              "      <td>191</td>\n",
              "      <td>...</td>\n",
              "      <td>154</td>\n",
              "      <td>124</td>\n",
              "      <td>138</td>\n",
              "      <td>143</td>\n",
              "      <td>111</td>\n",
              "      <td>126</td>\n",
              "      <td>129</td>\n",
              "      <td>100</td>\n",
              "      <td>111</td>\n",
              "      <td>102</td>\n",
              "      <td>74</td>\n",
              "      <td>80</td>\n",
              "      <td>94</td>\n",
              "      <td>73</td>\n",
              "      <td>86</td>\n",
              "      <td>74</td>\n",
              "      <td>47</td>\n",
              "      <td>61</td>\n",
              "      <td>52</td>\n",
              "      <td>32</td>\n",
              "      <td>45</td>\n",
              "      <td>33</td>\n",
              "      <td>17</td>\n",
              "      <td>25</td>\n",
              "      <td>28</td>\n",
              "      <td>13</td>\n",
              "      <td>19</td>\n",
              "      <td>27</td>\n",
              "      <td>13</td>\n",
              "      <td>17</td>\n",
              "      <td>27</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>138</td>\n",
              "      <td>94</td>\n",
              "      <td>117</td>\n",
              "      <td>158</td>\n",
              "      <td>113</td>\n",
              "      <td>138</td>\n",
              "      <td>178</td>\n",
              "      <td>133</td>\n",
              "      <td>161</td>\n",
              "      <td>191</td>\n",
              "      <td>143</td>\n",
              "      <td>172</td>\n",
              "      <td>202</td>\n",
              "      <td>150</td>\n",
              "      <td>173</td>\n",
              "      <td>212</td>\n",
              "      <td>160</td>\n",
              "      <td>185</td>\n",
              "      <td>216</td>\n",
              "      <td>162</td>\n",
              "      <td>191</td>\n",
              "      <td>222</td>\n",
              "      <td>175</td>\n",
              "      <td>209</td>\n",
              "      <td>227</td>\n",
              "      <td>183</td>\n",
              "      <td>219</td>\n",
              "      <td>229</td>\n",
              "      <td>183</td>\n",
              "      <td>216</td>\n",
              "      <td>232</td>\n",
              "      <td>188</td>\n",
              "      <td>221</td>\n",
              "      <td>234</td>\n",
              "      <td>193</td>\n",
              "      <td>222</td>\n",
              "      <td>234</td>\n",
              "      <td>191</td>\n",
              "      <td>218</td>\n",
              "      <td>235</td>\n",
              "      <td>...</td>\n",
              "      <td>221</td>\n",
              "      <td>169</td>\n",
              "      <td>202</td>\n",
              "      <td>226</td>\n",
              "      <td>167</td>\n",
              "      <td>201</td>\n",
              "      <td>226</td>\n",
              "      <td>164</td>\n",
              "      <td>197</td>\n",
              "      <td>224</td>\n",
              "      <td>176</td>\n",
              "      <td>203</td>\n",
              "      <td>224</td>\n",
              "      <td>178</td>\n",
              "      <td>206</td>\n",
              "      <td>222</td>\n",
              "      <td>181</td>\n",
              "      <td>206</td>\n",
              "      <td>213</td>\n",
              "      <td>170</td>\n",
              "      <td>191</td>\n",
              "      <td>200</td>\n",
              "      <td>155</td>\n",
              "      <td>177</td>\n",
              "      <td>187</td>\n",
              "      <td>148</td>\n",
              "      <td>164</td>\n",
              "      <td>164</td>\n",
              "      <td>128</td>\n",
              "      <td>140</td>\n",
              "      <td>140</td>\n",
              "      <td>106</td>\n",
              "      <td>118</td>\n",
              "      <td>108</td>\n",
              "      <td>77</td>\n",
              "      <td>92</td>\n",
              "      <td>67</td>\n",
              "      <td>40</td>\n",
              "      <td>55</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 12289 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel0000  pixel0001  pixel0002  ...  pixel12286  pixel12287  label\n",
              "0        191        152        194  ...         152         173      2\n",
              "1         24         13         23  ...          13          25      2\n",
              "2        185        129        140  ...          81          84      2\n",
              "3         24         11         19  ...           9          14      2\n",
              "4        138         94        117  ...          40          55      2\n",
              "\n",
              "[5 rows x 12289 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td19KUE-Pyez"
      },
      "source": [
        "X = data.drop(\"label\", axis=1).values\n",
        "label = data[\"label\"].values"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2DKINsLKwlI",
        "outputId": "9f000828-59ca-4685-a7ee-23481c012c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape, label.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10015, 12288), (10015,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRDQM312KgRQ"
      },
      "source": [
        "X_mean = np.mean(X)\n",
        "X_std = np.std(X)\n",
        "\n",
        "X = (X - X_mean)/X_std"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFrGGJ0GLR3a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test_temp,y_train,y_test_temp=train_test_split(X,label,test_size=0.1,random_state=42)\n",
        "X_val,X_test,y_val,y_test=train_test_split(X_test_temp,y_test_temp,test_size=.5,random_state=41)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWM8wJ2_Sazh",
        "outputId": "f8eaf77a-ed25-4f29-bd32-019863c3bd1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9013, 12288), (501, 12288), (9013,), (501,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5LTjLCOPyQ_"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "def pre_processing(X,Y):\n",
        "    X = X.reshape(-1,64,64,3)\n",
        "    X = X/255.0\n",
        "    Y = to_categorical(Y) \n",
        "    return X,Y"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QSeJgY2LtMw"
      },
      "source": [
        "X_train,y_train=pre_processing(X_train,y_train)\n",
        "X_test,y_test=pre_processing(X_test,y_test)\n",
        "X_val,y_val=pre_processing(X_val,y_val)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUTpC26VXHFL",
        "outputId": "fa0159ab-800e-4861-d918-3cb2a00c005a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X_train.shape, X_val.shape, X_test.shape,y_train.shape, y_val.shape, y_test.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9013, 64, 64, 3),\n",
              " (501, 64, 64, 3),\n",
              " (501, 64, 64, 3),\n",
              " (9013, 7),\n",
              " (501, 7),\n",
              " (501, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PT0vbO_YK4Z"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Activation,Dropout, Conv2D\n",
        "from keras.layers import AveragePooling2D,  MaxPooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import SeparableConv2D\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import  Adam"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2v7oDJR-dUV"
      },
      "source": [
        "# Our input feature map is 64x64x3: 64x64 for the image pixels, and 3 for\n",
        "# the three color channels: R, G, and B\n",
        "img_input = Input(shape=(64, 64, 3))\n",
        "\n",
        "# First convolution extracts 16 filters that are 3x3\n",
        "# Convolution is followed by max-pooling layer with a 2x2 window\n",
        "x = Conv2D(16, 3, activation='relu', padding='same')(img_input)\n",
        "x = MaxPooling2D(2)(x)\n",
        "\n",
        "# Second convolution extracts 32 filters that are 3x3\n",
        "# Convolution is followed by max-pooling layer with a 2x2 window\n",
        "x = Conv2D(32, 3, activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(2)(x)\n",
        "\n",
        "# Third convolution extracts 64 filters that are 3x3\n",
        "# Convolution is followed by max-pooling layer with a 2x2 window\n",
        "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(2)(x)\n",
        "\n",
        "# Flatten feature map to a 1-dim tensor\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Create a fully connected layer with ReLU activation and 512 hidden units\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "# Add a dropout rate of 0.5\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Create output layer with a single node and sigmoid activation\n",
        "output = Dense(7, activation='softmax')(x)\n",
        "\n",
        "# Configure and compile the model\n",
        "model = Model(img_input, output)\n",
        "\n",
        "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MceXzrIV-hYt",
        "outputId": "c3084c84-751f-436d-af0a-30213cdd6f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 64, 64, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 32, 32, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 7)                 3591      \n",
            "=================================================================\n",
            "Total params: 2,124,839\n",
            "Trainable params: 2,124,839\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYxzXM3W_Vmj"
      },
      "source": [
        "from keras.preprocessing.image import  ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2,\n",
        "                             shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
        "\n",
        "train_datagen.fit(X_train)\n",
        "\n",
        "val_datagen = ImageDataGenerator()\n",
        "val_datagen.fit(X_val)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9u4UubBBlIj"
      },
      "source": [
        "\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, \n",
        "                              factor=0.5, min_lr=0.00001)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9B3xkaFO30B"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 30"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mry-HtEaCXAj",
        "outputId": "e74dad08-eb95-4bae-cd1e-162c36aa1a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_datagen.flow(X_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = val_datagen.flow(X_val, y_val),\n",
        "                              verbose = 2, steps_per_epoch=(X_train.shape[0] // batch_size),\n",
        "                              callbacks=[reduce_lr])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.9385 - accuracy: 0.6707 - val_loss: 0.9222 - val_accuracy: 0.6547\n",
            "Epoch 2/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.9103 - accuracy: 0.6740 - val_loss: 0.8987 - val_accuracy: 0.6547\n",
            "Epoch 3/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.8833 - accuracy: 0.6745 - val_loss: 0.8921 - val_accuracy: 0.6587\n",
            "Epoch 4/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.8687 - accuracy: 0.6780 - val_loss: 0.8835 - val_accuracy: 0.6627\n",
            "Epoch 5/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.8617 - accuracy: 0.6906 - val_loss: 0.8466 - val_accuracy: 0.6846\n",
            "Epoch 6/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.8477 - accuracy: 0.6918 - val_loss: 0.8523 - val_accuracy: 0.6906\n",
            "Epoch 7/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.8429 - accuracy: 0.6940 - val_loss: 0.8382 - val_accuracy: 0.6826\n",
            "Epoch 8/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.8271 - accuracy: 0.6945 - val_loss: 0.8283 - val_accuracy: 0.6886\n",
            "Epoch 9/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.8223 - accuracy: 0.7007 - val_loss: 0.8188 - val_accuracy: 0.6906\n",
            "Epoch 10/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.8159 - accuracy: 0.7019 - val_loss: 0.8376 - val_accuracy: 0.6766\n",
            "Epoch 11/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.8120 - accuracy: 0.7007 - val_loss: 0.8137 - val_accuracy: 0.6946\n",
            "Epoch 12/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.7991 - accuracy: 0.7048 - val_loss: 0.8050 - val_accuracy: 0.7066\n",
            "Epoch 13/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.7968 - accuracy: 0.7077 - val_loss: 0.7724 - val_accuracy: 0.7046\n",
            "Epoch 14/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.7961 - accuracy: 0.7066 - val_loss: 0.7744 - val_accuracy: 0.7206\n",
            "Epoch 15/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.7783 - accuracy: 0.7123 - val_loss: 0.7608 - val_accuracy: 0.7026\n",
            "Epoch 16/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.7694 - accuracy: 0.7162 - val_loss: 0.7757 - val_accuracy: 0.7026\n",
            "Epoch 17/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.7559 - accuracy: 0.7216 - val_loss: 0.7598 - val_accuracy: 0.7026\n",
            "Epoch 18/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.7512 - accuracy: 0.7206 - val_loss: 0.7627 - val_accuracy: 0.7146\n",
            "Epoch 19/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.7431 - accuracy: 0.7252 - val_loss: 0.7297 - val_accuracy: 0.7146\n",
            "Epoch 20/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.7353 - accuracy: 0.7224 - val_loss: 0.7268 - val_accuracy: 0.7126\n",
            "Epoch 21/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.7205 - accuracy: 0.7272 - val_loss: 0.7112 - val_accuracy: 0.7246\n",
            "Epoch 22/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.7324 - accuracy: 0.7316 - val_loss: 0.7330 - val_accuracy: 0.7285\n",
            "Epoch 23/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.7152 - accuracy: 0.7310 - val_loss: 0.7029 - val_accuracy: 0.7285\n",
            "Epoch 24/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.7165 - accuracy: 0.7316 - val_loss: 0.7269 - val_accuracy: 0.7166\n",
            "Epoch 25/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.7031 - accuracy: 0.7354 - val_loss: 0.7129 - val_accuracy: 0.7445\n",
            "Epoch 26/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.6926 - accuracy: 0.7362 - val_loss: 0.6952 - val_accuracy: 0.7285\n",
            "Epoch 27/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.6939 - accuracy: 0.7395 - val_loss: 0.7054 - val_accuracy: 0.7265\n",
            "Epoch 28/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.6884 - accuracy: 0.7425 - val_loss: 0.7202 - val_accuracy: 0.7246\n",
            "Epoch 29/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.6887 - accuracy: 0.7386 - val_loss: 0.7039 - val_accuracy: 0.7365\n",
            "Epoch 30/30\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "140/140 - 9s - loss: 0.6810 - accuracy: 0.7415 - val_loss: 0.6827 - val_accuracy: 0.7425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfDBRKqeA30t",
        "outputId": "42cbe628-57e3-43a9-e38b-f60b6b6f63d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7089 - accuracy: 0.7445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7088739275932312, 0.7445109486579895]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPbNzaUaPdAW",
        "outputId": "e38ce4f2-e35b-4450-98f0-c22781ba665a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylim(.3, 1.0)\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training accuracy', 'Validation accuracy'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DepnuhKIQ4v4"
      },
      "source": [
        "\n",
        "lesion_type_dict = {\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Melanoma',\n",
        "    'bkl': 'Benign keratosis-like lesions ',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'akiec': 'Actinic keratoses',\n",
        "    'vasc': 'Vascular lesions',\n",
        "    'df': 'Dermatofibroma'\n",
        "}"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6XSQRV6Plnq",
        "outputId": "c1b85add-312b-4fcd-dff2-4d12bcad7bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# make predictions on the testing set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(X_val, batch_size=batch_size)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "from sklearn.metrics import classification_report\n",
        "target_names =[\"nv\", \"ml\",\"bkl\",\"bcc\",\"akice\",\"vasc\",\"df\"]\n",
        "print(classification_report(y_val.argmax(axis=1),\n",
        "                            predIdxs, target_names=target_names))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          nv       0.50      0.26      0.34        19\n",
            "          ml       0.59      0.71      0.65        28\n",
            "         bkl       0.45      0.31      0.37        54\n",
            "         bcc       1.00      0.17      0.29         6\n",
            "       akice       0.81      0.94      0.87       330\n",
            "        vasc       0.64      0.78      0.70         9\n",
            "          df       0.46      0.20      0.28        55\n",
            "\n",
            "    accuracy                           0.74       501\n",
            "   macro avg       0.63      0.48      0.50       501\n",
            "weighted avg       0.71      0.74      0.71       501\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}